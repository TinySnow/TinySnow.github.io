# 并行计算基础

## 复习

1. 了解了CPU的基本工作原理
2. 掌握了流水线技术的概念
3. 理解了缓存一致性问题

## TL;DR

- 并行计算通过多处理器协同工作提高性能
- 并行系统需要处理同步和通信问题
- 并行程序设计需要特殊的编程模型
- 并行性能受阿姆达尔定律限制

## 正文

### 并行计算基本概念

#### 1. 并行级别

1. **位级并行** ：
   ```
   8位加法器：  A7...A0 + B7...B0
   32位加法器： A31...A0 + B31...B0
   ```

2. **指令级并行** ：
   ```
   顺序执行：
   ADD R1,R2 → SUB R3,R4 → MUL R5,R6
   
   并行执行：
   ADD R1,R2
   SUB R3,R4  同时执行
   MUL R5,R6
   ```

3. **数据级并行** ：
   ```
   向量加法：
   A[0..7] + B[0..7] = C[0..7]
   同时计算8个元素
   ```

4. **任务级并行** ：
   ```
   任务1：图像处理
   任务2：音频处理
   任务3：网络通信
   同时在不同核心上执行
   ```

### 并行系统架构

#### 1. Flynn分类

1. **SISD（单指令单数据流）** ：
   ```
   传统单核处理器：
   指令流 → 处理器 → 数据流
   ```

2. **SIMD（单指令多数据流）** ：
   ```
   向量处理器：
   指令流 → 处理器1 → 数据流1
        → 处理器2 → 数据流2
        → 处理器3 → 数据流3
   ```

3. **MIMD（多指令多数据流）** ：
   ```
   多核处理器：
   指令流1 → 处理器1 → 数据流1
   指令流2 → 处理器2 → 数据流2
   指令流3 → 处理器3 → 数据流3
   ```

#### 2. 内存架构

1. **共享内存** ：
   ```
   CPU1 ↔ Cache1 ↘
   CPU2 ↔ Cache2 -→ 共享内存
   CPU3 ↔ Cache3 ↗
   ```

2. **分布式内存** ：
   ```
   CPU1 + 内存1 ↔ 网络 ↔ CPU2 + 内存2
   ```

### 并行程序设计

#### 1. 基本模式

1. **主从模式** ：
   ```
   主进程：
   - 分配任务
   - 收集结果
   - 协调工作
   
   从进程：
   - 执行任务
   - 返回结果
   ```

2. **流水线模式** ：
   ```
   阶段1 → 阶段2 → 阶段3 → 阶段4
   数据1    数据2    数据3    数据4
   ```

#### 2. 同步机制

1. **互斥锁** ：
   ```c
   mutex_lock(&lock);
   // 临界区
   shared_data++;
   mutex_unlock(&lock);
   ```

2. **信号量** ：
   ```c
   sem_wait(&empty);
   // 生产数据
   buffer[in] = item;
   sem_post(&full);
   ```

### 并行性能分析

#### 1. 阿姆达尔定律

1. **基本公式** ：
   ```
   加速比 = 1 / (s + p/n)
   s: 串行部分比例
   p: 并行部分比例
   n: 处理器数量
   ```

2. **实例分析** ：
   ```
   假设程序95%可并行：
   使用4个处理器：
   加速比 = 1 / (0.05 + 0.95/4) ≈ 3.48
   ```

#### 2. 性能优化

1. **负载均衡** ：
   ```
   任务分配：
   处理器1：30%
   处理器2：35%
   处理器3：35%
   ```

2. **通信开销** ：
   ```
   计算时间 vs 通信时间：
   粒度过细：通信开销大
   粒度过粗：负载不均衡
   ```

### 并行编程模型

#### 1. OpenMP

1. **基本用法** ：
   ```c
   #pragma omp parallel for
   for(int i = 0; i < n; i++) {
       result[i] = compute(data[i]);
   }
   ```

2. **数据共享** ：
   ```c
   #pragma omp parallel shared(sum) private(i)
   {
       local_sum = 0;
       #pragma omp for
       for(i = 0; i < n; i++)
           local_sum += array[i];
       
       #pragma omp critical
       sum += local_sum;
   }
   ```

#### 2. MPI

1. **消息传递** ：
   ```c
   MPI_Send(data, count, MPI_INT, dest, tag, comm);
   MPI_Recv(buf, count, MPI_INT, source, tag, comm, &status);
   ```

2. **集体通信** ：
   ```c
   MPI_Bcast(buffer, count, MPI_INT, root, comm);
   MPI_Reduce(sendbuf, recvbuf, count, MPI_INT, MPI_SUM, root, comm);
   ```

 **思考题** 

> 　　在设计一个并行算法时，如何选择合适的并行粒度？需要考虑哪些因素？

## 小结

### 知识点

- 并行计算的基本概念和级别
- 并行系统的架构类型
- 并行程序设计模式
- 并行性能分析方法

### 思考题答案（仅供参考）

　　选择并行粒度需考虑：

1. **计算特征** ：
   - 任务计算量
   - 数据依赖关系
   - 内存访问模式
   - 算法特性

2. **系统特征** ：
   - 处理器数量
   - 通信带宽
   - 内存架构
   - 缓存特性

3. **性能目标** ：
   - 响应时间要求
   - 吞吐量要求
   - 资源利用率
   - 能耗效率

4. **实现复杂度** ：
   - 开发难度
   - 调试难度
   - 可维护性
   - 可扩展性

## 参考资料

1. [Wikipedia(zh)：并行计算](https://zh.wikipedia.org/wiki/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97)：并行计算的基本概念
2. [Wikipedia(zh)：OpenMP](https://zh.wikipedia.org/wiki/OpenMP)：OpenMP并行编程模型
3. [Wikipedia(zh)：消息传递接口](https://zh.wikipedia.org/wiki/%E8%A8%8A%E6%81%AF%E5%82%B3%E9%81%9E%E4%BB%8B%E9%9D%A2)：MPI编程模型

## 协议

　　本作品采用[知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)进行许可。
